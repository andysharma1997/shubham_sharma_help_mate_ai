chunk_settings:
  chunk_size: 500
  chunk_overlap: 50

models:
  embedding_model: 
    name: all-MiniLM-L6-v2
    batch_size: 32 #change the batch_size according to gpu vRAM or if the model is loaded on cpu then based on the RAM.
  re-ranker:
    name: cross-encoder/ms-marco-MiniLM-L-6-v2
    batch_size: 16


vector_store_settings:
  persist_directory: ./chroma_db
  collection_name: insurance
  top_k: 10

generation_config:
  model_name: gpt-4o-mini
  temprature: 0.7
